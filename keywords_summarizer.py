import requests
import xml.etree.ElementTree as ET
import os
import time
from datetime import datetime, timedelta

# 1. è·å–å¯†é’¥
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', '').strip()
PUSH_KEY = os.environ.get('PUSH_KEY', '').strip()

def summarize_with_gemini(abstract):
    """æç®€è°ƒç”¨ï¼Œæ’é™¤æ‰€æœ‰éå¿…è¦å‚æ•°"""
    # å¼ºåˆ¶å°è¯•æœ€é€šç”¨çš„ v1 ç‰ˆæœ¬æ¥å£
    url = f"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key={GEMINI_API_KEY}"
    payload = {"contents": [{"parts": [{"text": f"è¯·ç”¨ä¸­æ–‡æ€»ç»“è¿™æ®µæ‘˜è¦ï¼ˆ1-2å¥ï¼‰ï¼š\n\n{abstract}"}]}]}
    try:
        response = requests.post(url, json=payload, timeout=20)
        res_json = response.json()
        if 'candidates' in res_json:
            return res_json['candidates'][0]['content']['parts'][0]['text'].strip()
        # å¦‚æœæŠ¥é”™ï¼ŒæŠŠåŸå§‹æŠ¥é”™çš„å‰ 30 ä¸ªå­—å‘å‡ºæ¥
        return f"æ€»ç»“å¤±è´¥ï¼š{str(res_json.get('error', {}).get('message', 'APIæ— å“åº”'))[:30]}"
    except:
        return "ç½‘ç»œè¯·æ±‚å¼‚å¸¸"

def fetch_papers(kw):
    """å¸¦åŸºç¡€å®¹é”™çš„æŠ“å–"""
    # å®éªŒæ¨¡å¼ï¼šæœæœ€è¿‘ 7 å¤©ï¼Œç¡®ä¿æœ‰æ•°æ®åˆä¸å®¹æ˜“è¢«å°
    start = (datetime.now() - timedelta(days=7)).strftime("%Y%m%d%H%M%S")
    url = f"http://export.arxiv.org/api/query?search_query=all:\"{kw}\"+AND+submittedDate:[{start}+TO+20261231235959]&max_results=2"
    try:
        r = requests.get(url, timeout=15)
        root = ET.fromstring(r.content)
        papers = []
        for e in root.findall('{http://www.w3.org/2005/Atom}entry'):
            title = e.find('{http://www.w3.org/2005/Atom}title').text.strip().replace('\n', ' ')
            summary = e.find('{http://www.w3.org/2005/Atom}summary').text.strip().replace('\n', ' ')
            link = e.find('{http://www.w3.org/2005/Atom}link[@title="pdf"]').attrib['href']
            papers.append({'title': title, 'summary': summary, 'link': link, 'kw': kw})
        return papers
    except:
        return []

if __name__ == "__main__":
    # ä¸ºäº†æµ‹è¯•ï¼Œæˆ‘ä»¬ç”¨ä¸€ä¸ªå¿…ç„¶æœ‰è®ºæ–‡çš„è¯
    keywords = ["Machine Learning", "Transformer"]
    final_content = ""
    
    print("å¼€å§‹æŠ“å–æµ‹è¯•è®ºæ–‡...")
    for kw in keywords:
        papers = fetch_papers(kw)
        print(f"å…³é”®è¯ ã€{kw}ã€‘ æ‰¾åˆ° {len(papers)} ç¯‡")
        for p in papers:
            summary = summarize_with_gemini(p['summary'])
            final_content += f"ã€{p['kw']}ã€‘\næ ‡é¢˜ï¼š{p['title']}\næ€»ç»“ï¼š{summary}\né“¾æ¥ï¼š{p['link']}\n\n"
            time.sleep(2)

    if PUSH_KEY:
        title = f"å®éªŒæ¨é€-{datetime.now().strftime('%m/%d')}"
        desp = "ğŸ’¡ æ¨é€å®éªŒç»“æœï¼š\n\n" + final_content if final_content else "ä»Šæ—¥æ— è®ºæ–‡æŠ“å–"
        requests.post(f"https://sctapi.ftqq.com/{PUSH_KEY}.send", data={"title": title, "desp": desp})
    print("ä»»åŠ¡æ‰§è¡Œå®Œæ¯•")
